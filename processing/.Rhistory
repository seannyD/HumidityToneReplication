agreement.cons = rbind(agreement.cons,
c(x,y,agr$weighted.kappa,cor,nrow(dx)))
}
}
}
agreement.cons$n = as.numeric(agreement.cons$n)
agreement.cons = agreement.cons[!is.na(agreement.cons$agreement),]
agreement.cons = agreement.cons[agreement.cons$n > 20,]
agreement.cons
######
# Add autotyp areas
load("~/Documents/MPI/Neandertals_Collab/fossil/autotyp.data/autotyp.backbone.rda")
autotyp.backbone$glottolog_LID.2014 =as.character(autotyp.backbone$glottolog_LID.2014)
autotyp.backbone$area =as.character(autotyp.backbone$area)
# Find actual matches by glottoID
p$autotyp.area = autotyp.backbone[match(p$Glottocode,autotyp.backbone$glottolog_LID.2014),]$area
# split into found and missing
atFound = as.matrix(p[!is.na(p$autotyp.area),c("Longitude","Latitude")])
atMissing = as.matrix(p[is.na(p$autotyp.area),c("Longitude","Latitude")])
# For missing, find area of closest langauge
atDist = rdist.earth(atFound,atMissing)
closestArea = p[!is.na(p$autotyp.area),]$autotyp.area[apply(atDist,2,function(X){which(X==min(X,na.rm=T),arr.ind=T)[1]})]
p[is.na(p$autotyp.area),]$autotyp.area = closestArea
p = p[!(is.na(p$autotyp.area) & is.na(p$Longitude)),]
p.vowels = p
p.vowels$TrumpScore = (p.vowels$Trump*20) + as.numeric(p.vowels$Source)
p.vowels = p.vowels %>%
group_by(Glottocode) %>%
top_n(n = 1, wt = TrumpScore)
write.csv(p.vowels,"../data/phoibleVowelsAndHumidity.csv")
####
# Some sources have no info on tone segments
tapply(p$Tones, p$Source, sum,na.rm=T)
p = p[!p$Source %in% c("ea",'upsid','saphon','ra'),]
# Take the explicitly marked trump inventory, or the one with the highest number of segments counted
p$TrumpScore = (p$Trump*20) + as.numeric(p$Source)
p = p %>%
group_by(Glottocode) %>%
top_n(n = 1, wt = TrumpScore)
write.csv(p,"../data/phoibleTonesAndHumidity.csv")
boxplot(p$specH.mean~p$Tones)
library(gplots)
plotmeans(specH.mean~cut(Tones,c(-1,1,2,3,4,12)),data=p[p$Tones!=1,], connect = F)
plotmeans(specH.mean~cut(Tones,c(-1,2,3,Inf)),data=p[p$Tones!=1,], connect = F)
ggplot(p[p$Tones!=1,], aes(x=cut(Tones,c(-1,3,4,Inf)), y=specH.mean)) +
geom_violin()
makeCumDistGraph = function(d,var="specH.mean",quantileLines=F,lex=0.001,ley=0.9,xlab="Mean Specific Humidity",cutoff=3,qLinePerCat=F){
cat1 = d$Tones==0 & !is.na(d[,var])
cat2 = d$Tones>0 & d$Tones<=cutoff & !is.na(d[,var])
cat3 = d$Tones>cutoff  & !is.na(d[,var])
plot(ecdf(d[cat1,var]),col=colx[1],main='',xlab=xlab,pch=NA,verticals=T)
if(quantileLines){
#abline(v=quantile(d[!is.na(d[,var]),var])[2:4],lty=1,col='gray')
qt = quantile(d[!is.na(d[,var]),var])
rect(qt[1],0,qt[2],1,col='#f0f0f0',border=NA)
lines(ecdf(d[cat1,var]),col=colx[1],lty=ltyx[1],pch=NA,verticals=T)
}
#text(quantile(d$specH.mean),150,c("1st Quartile","2nd Quartile",'3rd Quartile','4th Quartile'))
lines(ecdf(d[cat2,var]),col=colx[2],lty=ltyx[2],pch=NA,verticals=T)
lines(ecdf(d[cat3,var]),col=colx[3],lty=ltyx[3],pch=NA,verticals=T)
if(qLinePerCat){
q1= quantile(d[cat1,var],c(0.25,0.75))
q2= quantile(d[cat2,var],c(0.25,0.75))
q3= quantile(d[cat3,var],c(0.25,0.75))
abline(v=c(q1,q2,q3),col=rep(colx,each=2))
}
legend(lex,ley,legend=c("No tones",">0 tones",paste(">",cutoff," tones",sep='')),col=colx,bg='white',lty=ltyx,lwd=2)
}
d2 = p[!is.na(p$specH.mean),]
d2 = p[!is.na(d2$Tones),]
d2 = as.data.frame(d2)
colx = c("#fdcc8a","#fc8d59","#d7301f") #colorbrewer sequential colourblind safe, print safe, photocopy safe.
ltyx=rep(1,3)
scaleX=1.5
pdf("../results/CumDistGraph_PHOIBLE.pdf",width=3.42*scaleX,height=3*scaleX)
makeCumDistGraph(d2,quantileLines=T,qLinePerCat=F)
dev.off()
agreement.cons = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Cons.",sources)){
for(y in paste0("Cons.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)])))
cor = cor(dx[,x],dx[,y])
agreement.cons = rbind(agreement.cons,
c(x,y,agr$weighted.kappa,cor,nrow(dx)))
}
}
}
agreement.cons$n = as.numeric(agreement.cons$n)
agreement.cons = agreement.cons[!is.na(agreement.cons$agreement),]
agreement.cons = agreement.cons[agreement.cons$n > 20,]
agreement.cons
agreement.vow = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Vowels.",sources)){
for(y in paste0("Vowels.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)])))
cor = cor(dx[,x],dx[,y])
agreement.vow = rbind(agreement.vow,
c(x,y,agr$weighted.kappa,cor,nrow(dx)))
}
}
}
agreement.vow$n = as.numeric(agreement.vow$n)
agreement.vow = agreement.vow[!is.na(agreement.vow$agreement),]
agreement.vow = agreement.vow[agreement.vow$n > 20,]
agreement.vow
agreement = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Tones.",sources)){
for(y in paste0("Tones.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)])))
cor = cor(dx[,x],dx[,y])
agreement = rbind(agreement,
c(x,y,agr$weighted.kappa,cor,nrow(dx)))
}
}
}
agreement$n = as.numeric(agreement$n)
agreement = agreement[!is.na(agreement$agreement),]
agreement = agreement[agreement$n > 20,]
agreement
agx
x
paste0("Tones.",sources)
paste0("Tones.",sources)
y
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
agr <- cohen.kappa(as.matrix(dx[,c(x,y)]))
dx
cor = cor(dx[,x],dx[,y])
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)])))
cor = cor(dx[,x],dx[,y])
cor
c(x,y,agr$weighted.kappa,cor,nrow(dx))
agreement = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Tones.",sources)){
for(y in paste0("Tones.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)]))$weighted.kappa)
cor = cor(dx[,x],dx[,y])
agreement = rbind(agreement,
c(x,y,agr,cor,nrow(dx)))
}
}
}
agreement$n = as.numeric(agreement$n)
agreement = agreement[!is.na(agreement$agreement),]
agreement = agreement[agreement$n > 20,]
agreement
x
paste0("Tones.",sources)
sources =  c("aa",'spa','gm','uz','ph')
for(x in sources){
dx= p[p$Source==x,]
langs[,paste0("Tones.",x)] = dx[match(langs$Glottocode,dx$Glottocode),]$Tones
langs[,paste0("Vowels.",x)] = dx[match(langs$Glottocode,dx$Glottocode),]$Vowels
langs[,paste0("Cons.",x)] = dx[match(langs$Glottocode,dx$Glottocode),]$Consonants
}
agreement = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Tones.",sources)){
for(y in paste0("Tones.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)]))$weighted.kappa)
cor = cor(dx[,x],dx[,y])
agreement = rbind(agreement,
c(x,y,agr,cor,nrow(dx)))
}
}
}
agreement$n = as.numeric(agreement$n)
agreement = agreement[!is.na(agreement$agreement),]
agreement = agreement[agreement$n > 20,]
agreement
plot(langs$Tones.aa, langs$Tones.spa)
# Test agreement in vowels
agreement.vow = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Vowels.",sources)){
for(y in paste0("Vowels.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)]))$weighted.kappa)
cor = cor(dx[,x],dx[,y])
agreement.vow = rbind(agreement.vow,
c(x,y,agr,cor,nrow(dx)))
}
}
}
agreement.vow$n = as.numeric(agreement.vow$n)
agreement.vow = agreement.vow[!is.na(agreement.vow$agreement),]
agreement.vow = agreement.vow[agreement.vow$n > 20,]
agreement.vow
# Test agreement in consonants
agreement.cons = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Cons.",sources)){
for(y in paste0("Cons.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)]))$weighted.kappa)
cor = cor(dx[,x],dx[,y])
agreement.cons = rbind(agreement.cons,
c(x,y,agr,cor,nrow(dx)))
}
}
}
agreement.cons$n = as.numeric(agreement.cons$n)
agreement.cons = agreement.cons[!is.na(agreement.cons$agreement),]
agreement.cons = agreement.cons[agreement.cons$n > 20,]
agreement.cons
library(ggplot2)
library(fields)
library(dplyr)
setwd("~/Documents/MPI/ClimateAndLanguage/PHOIBLE_Replication/processing/")
rotate <- function(x) t(apply(x, 2, rev))
phoible.langs = read.delim("../data/InventoryID-LanguageCodes.tsv", sep='\t', stringsAsFactors = F, fileEncoding = 'utf-8')
load("../data/phoible-by-phoneme.RData")
final.data$tone = as.numeric(final.data$tone=="+")
vowels <- c("i", "y", "ɨ", "ʉ", "ɯ", "u", "ɪ", "ʏ", "ʊ", "e", "ø", "ɘ", "ɵ",
"ɤ", "o", "ə", "ɛ", "œ", "ɜ", "ɞ", "ʌ", "ɔ", "æ", "ɐ", "a", "ɶ",
"ɑ", "ɒ", "ɚ", "ɝ","a"  ,    "æ"   ,   "ɐ"  ,    "ɑ"  ,    "ɒ",'ə',
"ɛ"   ,   "ɘ"    ,  "ɜ", "i"   ,   "ɪ" , "ɨ","ɰ"  ,    "ʊ"  , "ɯ","u" ,
"ʉ"  ,    "ɥ", "œ"   ,   "ɶ"   ,   "ɔ", "o"   ,   "ø", 'ʏ','ɯ')
final.data$vowel = grepl(paste0("[",paste0(vowels, collapse=""),"]"),
final.data$Phoneme) & final.data$sonorant =="+"
p = final.data %>% group_by(LanguageName, LanguageCode, Source, InventoryID, Trump) %>%
summarise(Tones = sum(tone, na.rm=T),
Vowels = sum(vowel, na.rm=T),
inventorySize=length(Phoneme),
Sonorants = sum(sonorant=="+", na.rm=T))
# Consonants are actually non-vowels
p$Consonants = p$inventorySize - p$Vowels
p$Glottocode = phoible.langs[match(p$LanguageCode, phoible.langs$LanguageCode),]$Glottocode
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
g$family = g[match(g$family_pk,g$pk),]$name
p$LanguageFamilyRoot = g[match(p$Glottocode, g$id),]$family
p$Latitude = g[match(p$Glottocode,g$id),]$latitude
p$Longitude = g[match(p$Glottocode,g$id),]$longitude
# take out langs with missing geo data
p = p[!is.na(p$Longitude),]
p = p[!is.na(p$LanguageFamilyRoot),]
##
# Load humidity data
h.mean = read.csv("../data/MeanMonthlyMeans.csv")
h.mean = as.matrix(h.mean[,c(2:ncol(h.mean))])
cols = 190
rows = 94
p$Latitude = as.numeric(p$Latitude)
p$Longitude = as.numeric(p$Longitude)
p$Latitude.grid = as.numeric(cut(p$Latitude,seq(90,-90,length.out=rows)))
p$Longitude.grid = as.numeric(cut(p$Longitude,seq(-180,180,length.out=cols)))
p$specH.mean = apply(cbind(p$Latitude.grid,p$Longitude.grid),1,function(X){h.mean[X[2],X[1]]})
p$Family = p$LanguageFamilyRoot
# Number unclassifieds
p$Family[p$Family=="Unclassifiable"] = paste(p$Family[p$Family=="Unclassifiable"],1:(sum(p$Family=="Unclassifiable")))
p$gFam = p$Family
####
# Test agreement between langauges
langs = p[!duplicated(p$Glottocode),]
sources =  c("aa",'spa','gm','uz','ph')
for(x in sources){
dx= p[p$Source==x,]
langs[,paste0("Tones.",x)] = dx[match(langs$Glottocode,dx$Glottocode),]$Tones
langs[,paste0("Vowels.",x)] = dx[match(langs$Glottocode,dx$Glottocode),]$Vowels
langs[,paste0("Cons.",x)] = dx[match(langs$Glottocode,dx$Glottocode),]$Consonants
}
agreement = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Tones.",sources)){
for(y in paste0("Tones.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)]))$weighted.kappa)
cor = cor(dx[,x],dx[,y])
agreement = rbind(agreement,
c(x,y,agr,cor,nrow(dx)))
}
}
}
agreement$n = as.numeric(agreement$n)
agreement = agreement[!is.na(agreement$agreement),]
agreement = agreement[agreement$n > 20,]
agreement
agreement.vow = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Vowels.",sources)){
for(y in paste0("Vowels.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)]))$weighted.kappa)
cor = cor(dx[,x],dx[,y])
agreement.vow = rbind(agreement.vow,
c(x,y,agr,cor,nrow(dx)))
}
}
}
agreement.vow$n = as.numeric(agreement.vow$n)
agreement.vow = agreement.vow[!is.na(agreement.vow$agreement),]
agreement.vow = agreement.vow[agreement.vow$n > 20,]
agreement.vow
agreement.cons = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Cons.",sources)){
for(y in paste0("Cons.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)]))$weighted.kappa)
cor = cor(dx[,x],dx[,y])
agreement.cons = rbind(agreement.cons,
c(x,y,agr,cor,nrow(dx)))
}
}
}
agreement.cons$n = as.numeric(agreement.cons$n)
agreement.cons = agreement.cons[!is.na(agreement.cons$agreement),]
agreement.cons = agreement.cons[agreement.cons$n > 20,]
agreement.cons
library(ggplot2)
library(fields)
library(dplyr)
setwd("~/Documents/MPI/ClimateAndLanguage/PHOIBLE_Replication/processing/")
rotate <- function(x) t(apply(x, 2, rev))
phoible.langs = read.delim("../data/InventoryID-LanguageCodes.tsv", sep='\t', stringsAsFactors = F, fileEncoding = 'utf-8')
load("../data/phoible-by-phoneme.RData")
final.data$tone = as.numeric(final.data$tone=="+")
vowels <- c("i", "y", "ɨ", "ʉ", "ɯ", "u", "ɪ", "ʏ", "ʊ", "e", "ø", "ɘ", "ɵ",
"ɤ", "o", "ə", "ɛ", "œ", "ɜ", "ɞ", "ʌ", "ɔ", "æ", "ɐ", "a", "ɶ",
"ɑ", "ɒ", "ɚ", "ɝ","a"  ,    "æ"   ,   "ɐ"  ,    "ɑ"  ,    "ɒ",'ə',
"ɛ"   ,   "ɘ"    ,  "ɜ", "i"   ,   "ɪ" , "ɨ","ɰ"  ,    "ʊ"  , "ɯ","u" ,
"ʉ"  ,    "ɥ", "œ"   ,   "ɶ"   ,   "ɔ", "o"   ,   "ø", 'ʏ','ɯ')
final.data$vowel = grepl(paste0("[",paste0(vowels, collapse=""),"]"),
final.data$Phoneme) & final.data$sonorant =="+"
p = final.data %>% group_by(LanguageName, LanguageCode, Source, InventoryID, Trump) %>%
summarise(Tones = sum(tone, na.rm=T),
Vowels = sum(vowel, na.rm=T),
inventorySize=length(Phoneme),
Sonorants = sum(sonorant=="+", na.rm=T))
# Consonants are actually non-vowels
p$Consonants = p$inventorySize - p$Vowels
p$Glottocode = phoible.langs[match(p$LanguageCode, phoible.langs$LanguageCode),]$Glottocode
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
g$family = g[match(g$family_pk,g$pk),]$name
p$LanguageFamilyRoot = g[match(p$Glottocode, g$id),]$family
p$Latitude = g[match(p$Glottocode,g$id),]$latitude
p$Longitude = g[match(p$Glottocode,g$id),]$longitude
# take out langs with missing geo data
p = p[!is.na(p$Longitude),]
p = p[!is.na(p$LanguageFamilyRoot),]
##
# Load humidity data
h.mean = read.csv("../data/MeanMonthlyMeans.csv")
h.mean = as.matrix(h.mean[,c(2:ncol(h.mean))])
cols = 190
rows = 94
p$Latitude = as.numeric(p$Latitude)
p$Longitude = as.numeric(p$Longitude)
p$Latitude.grid = as.numeric(cut(p$Latitude,seq(90,-90,length.out=rows)))
p$Longitude.grid = as.numeric(cut(p$Longitude,seq(-180,180,length.out=cols)))
p$specH.mean = apply(cbind(p$Latitude.grid,p$Longitude.grid),1,function(X){h.mean[X[2],X[1]]})
p$Family = p$LanguageFamilyRoot
# Number unclassifieds
p$Family[p$Family=="Unclassifiable"] = paste(p$Family[p$Family=="Unclassifiable"],1:(sum(p$Family=="Unclassifiable")))
p$gFam = p$Family
####
# Test agreement between langauges
langs = p[!duplicated(p$Glottocode),]
sources =  c("aa",'spa','gm','uz','ph')
for(x in sources){
dx= p[p$Source==x,]
langs[,paste0("Tones.",x)] = dx[match(langs$Glottocode,dx$Glottocode),]$Tones
langs[,paste0("Vowels.",x)] = dx[match(langs$Glottocode,dx$Glottocode),]$Vowels
langs[,paste0("Cons.",x)] = dx[match(langs$Glottocode,dx$Glottocode),]$Consonants
}
agreement = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Tones.",sources)){
for(y in paste0("Tones.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)]))$weighted.kappa)
cor = cor(dx[,x],dx[,y])
agreement = rbind(agreement,
c(x,y,agr,cor,nrow(dx)))
}
}
}
agreement$n = as.numeric(agreement$n)
agreement = agreement[!is.na(agreement$agreement),]
agreement = agreement[agreement$n > 20,]
agreement
plot(langs$Tones.aa, langs$Tones.spa)
# Test agreement in vowels
agreement.vow = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Vowels.",sources)){
for(y in paste0("Vowels.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)]))$weighted.kappa)
cor = cor(dx[,x],dx[,y])
agreement.vow = rbind(agreement.vow,
c(x,y,agr,cor,nrow(dx)))
}
}
}
agreement.vow$n = as.numeric(agreement.vow$n)
agreement.vow = agreement.vow[!is.na(agreement.vow$agreement),]
agreement.vow = agreement.vow[agreement.vow$n > 20,]
agreement.vow
# Test agreement in consonants
agreement.cons = data.frame(s1=NA,s2=NA, agreement = NA, cor=NA,n=NA)
for(x in paste0("Cons.",sources)){
for(y in paste0("Cons.",sources)){
if(x!=y){
dx = langs[(!is.na(langs[,x])) & (!is.na(langs[,y])),]
agr = NA
try(agr <- cohen.kappa(as.matrix(dx[,c(x,y)]))$weighted.kappa)
cor = cor(dx[,x],dx[,y])
agreement.cons = rbind(agreement.cons,
c(x,y,agr,cor,nrow(dx)))
}
}
}
agreement.cons$n = as.numeric(agreement.cons$n)
agreement.cons = agreement.cons[!is.na(agreement.cons$agreement),]
agreement.cons = agreement.cons[agreement.cons$n > 20,]
agreement.cons
######
# Add autotyp areas
load("~/Documents/MPI/Neandertals_Collab/fossil/autotyp.data/autotyp.backbone.rda")
autotyp.backbone$glottolog_LID.2014 =as.character(autotyp.backbone$glottolog_LID.2014)
autotyp.backbone$area =as.character(autotyp.backbone$area)
# Find actual matches by glottoID
p$autotyp.area = autotyp.backbone[match(p$Glottocode,autotyp.backbone$glottolog_LID.2014),]$area
# split into found and missing
atFound = as.matrix(p[!is.na(p$autotyp.area),c("Longitude","Latitude")])
atMissing = as.matrix(p[is.na(p$autotyp.area),c("Longitude","Latitude")])
# For missing, find area of closest langauge
atDist = rdist.earth(atFound,atMissing)
closestArea = p[!is.na(p$autotyp.area),]$autotyp.area[apply(atDist,2,function(X){which(X==min(X,na.rm=T),arr.ind=T)[1]})]
p[is.na(p$autotyp.area),]$autotyp.area = closestArea
p = p[!(is.na(p$autotyp.area) & is.na(p$Longitude)),]
p.vowels = p
p.vowels$TrumpScore = (p.vowels$Trump*20) + as.numeric(p.vowels$Source)
p.vowels = p.vowels %>%
group_by(Glottocode) %>%
top_n(n = 1, wt = TrumpScore)
write.csv(p.vowels,"../data/phoibleVowelsAndHumidity.csv")
####
# Some sources have no info on tone segments
tapply(p$Tones, p$Source, sum,na.rm=T)
p = p[!p$Source %in% c("ea",'upsid','saphon','ra'),]
# Take the explicitly marked trump inventory, or the one with the highest number of segments counted
p$TrumpScore = (p$Trump*20) + as.numeric(p$Source)
p = p %>%
group_by(Glottocode) %>%
top_n(n = 1, wt = TrumpScore)
write.csv(p,"../data/phoibleTonesAndHumidity.csv")
boxplot(p$specH.mean~p$Tones)
library(gplots)
plotmeans(specH.mean~cut(Tones,c(-1,1,2,3,4,12)),data=p[p$Tones!=1,], connect = F)
plotmeans(specH.mean~cut(Tones,c(-1,2,3,Inf)),data=p[p$Tones!=1,], connect = F)
ggplot(p[p$Tones!=1,], aes(x=cut(Tones,c(-1,3,4,Inf)), y=specH.mean)) +
geom_violin()
makeCumDistGraph = function(d,var="specH.mean",quantileLines=F,lex=0.001,ley=0.9,xlab="Mean Specific Humidity",cutoff=3,qLinePerCat=F){
cat1 = d$Tones==0 & !is.na(d[,var])
cat2 = d$Tones>0 & d$Tones<=cutoff & !is.na(d[,var])
cat3 = d$Tones>cutoff  & !is.na(d[,var])
plot(ecdf(d[cat1,var]),col=colx[1],main='',xlab=xlab,pch=NA,verticals=T)
if(quantileLines){
#abline(v=quantile(d[!is.na(d[,var]),var])[2:4],lty=1,col='gray')
qt = quantile(d[!is.na(d[,var]),var])
rect(qt[1],0,qt[2],1,col='#f0f0f0',border=NA)
lines(ecdf(d[cat1,var]),col=colx[1],lty=ltyx[1],pch=NA,verticals=T)
}
#text(quantile(d$specH.mean),150,c("1st Quartile","2nd Quartile",'3rd Quartile','4th Quartile'))
lines(ecdf(d[cat2,var]),col=colx[2],lty=ltyx[2],pch=NA,verticals=T)
lines(ecdf(d[cat3,var]),col=colx[3],lty=ltyx[3],pch=NA,verticals=T)
if(qLinePerCat){
q1= quantile(d[cat1,var],c(0.25,0.75))
q2= quantile(d[cat2,var],c(0.25,0.75))
q3= quantile(d[cat3,var],c(0.25,0.75))
abline(v=c(q1,q2,q3),col=rep(colx,each=2))
}
legend(lex,ley,legend=c("No tones",">0 tones",paste(">",cutoff," tones",sep='')),col=colx,bg='white',lty=ltyx,lwd=2)
}
d2 = p[!is.na(p$specH.mean),]
d2 = p[!is.na(d2$Tones),]
d2 = as.data.frame(d2)
colx = c("#fdcc8a","#fc8d59","#d7301f") #colorbrewer sequential colourblind safe, print safe, photocopy safe.
ltyx=rep(1,3)
scaleX=1.5
pdf("../results/CumDistGraph_PHOIBLE.pdf",width=3.42*scaleX,height=3*scaleX)
makeCumDistGraph(d2,quantileLines=T,qLinePerCat=F)
dev.off()
library(MCMCglmm)
cite(MCMCglmm)
cite('MCMCglmm')
citation('MCMCglmm')
