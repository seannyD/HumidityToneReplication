as.Date(2017-01-01)
abline(h=as.Date("2017-01-01"))
abline(v=as.Date("2017-01-01"))
abline(v=as.Date("2017-02-01"))
abline(v=as.Date("2017-03-01"))
d
d[45:46,]
factor(10)
factorial(10)
factorial(20)
numberOfSamples = 137
numberOfSamples/2
68 + 68
d = read.csv("~/Documents/MPI/LuisM_K_Pronoun/data/Alldata_simple.csv", stringsAsFactors = F)
head(d)
names(d)
g = read.csv("~/Documents/MPI/Glottolog/glottolog-languoid.csv/languoid.csv",stringsAsFactors = F)
names(g)
g$family = g[match(g$family_pk,g$pk),]$name
head(g$id)
d$family = g[match(d$glotto,g$id),]$family
head(d$family)
table(d$family)
d2 = d[d$family=="Uto-Aztecan",]
table(d2$meaning.id)
table(d2$Language)
d = read.delim("~/Documents/MPI/LuisM_K_Pronoun/BEAST_analysis/models/2017/relaxedClock_excludeSmall/relaxedClock_resampled.log",sep="\t", skip = 790, nrows = 10)
head(d)
plot(d$posterior)
d = read.delim("~/Documents/MPI/LuisM_K_Pronoun/BEAST_analysis/models/2017/relaxedClock_excludeSmall/relaxedClock_resampled.log",sep="\t", skip = 790, nrows = 20000)
plot(d$posterior)
plot(log(d$posterior))
plot(log(absd$posterior))
plot(log(abs(d$posterior)))
plot((d$posterior))
plot((d$posterior[3:nrow(d)]))
library(RColorBrewer)
RColorBrewer::display.brewer.all()
?RColorBrewer::display.brewer.all()
?display.brewer.all()
RColorBrewer::display.brewer.all(colorblindFriendly=T)
?display.brewer.all(colorblindFriendly=T)
brewer.pal(4,'Dark2')
plot(1:4,col=brewer.pal(4,'Dark2'),pch=15, cex=4)
plot(1:4,col=brewer.pal(4,'Set2'),pch=15, cex=4)
plot(1:6,col=brewer.pal(6,'Set2'),pch=15, cex=4)
plot(1:6,col=brewer.pal(6,'Dark2'),pch=15, cex=4)
pi
pi*0.5
library(ape)
setwd("~/Documents/MPI/ClimateAndLanguage/PHOIBLE_Replication/analysis/")
source("fitPagel.r")
runDiscrete = function(tree,x,y, iQ, dQ){
# fit discrete
fit.ape = NA
try(fit.ape<-fitPagel(tree,x,y,iQ=iQ,dQ=dQ,method='ace'))
return(list(list(fit.ape,table(x,y),qx)))
}
# single-rate model
iQ<-matrix(c(0,1,2,0,3,0,0,2,4,0,0,1,0,4,3,0),4,4,byrow=TRUE)
# differet rates for complex -> simple in humid and dry conditions
dQ =matrix(c(0,1,2,0,3,0,0,5,4,0,0,1,0,4,3,0),4,4,byrow=TRUE)
tree = read.nexus("../data/grollemund_et_al2015-d-place.NEXUS")
tree.t = read.csv("../data/grollemund_et_al2015-d-place_Taxa.csv", stringsAsFactors = F)
tree$tip.label = tree.t[match(tree$tip.label, tree.t$taxon),]$glottocode
p = read.csv("../data/phoibleTonesAndHumidity.csv", stringsAsFactors = F)
load('../../Phylogenetics/GlottologTree/ANU_Data.rDat')
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
anu$glottocode = g[match(anu$iso, g$hid),]$id
anu = anu[!is.na(anu$glottocode),]
anu = anu[!anu$glottocode %in% p$Glottocode,]
names(anu)[names(anu) %in% c("Number.of.tones","glottocode")] = c("Tones","Glottocode")
comb = rbind(anu[,c("Glottocode","Tones",'specH.mean')],
p[,c("Glottocode","Tones",'specH.mean')])
tree = drop.tip(tree, tree$tip.label[!tree$tip.label %in% comb$Glottocode])
tones = comb[match(tree$tip.label, comb$Glottocode),]$Tones
names(tones) = comb[match(tree$tip.label, comb$Glottocode),]$Glottocode
humidity = comb[match(tree$tip.label, comb$Glottocode),]$specH.mean
names(humidity) = comb[match(tree$tip.label, comb$Glottocode),]$Glottocode
tones.bin = tones>=3
# Estimate quantiles from whole distribution
quantilesToRun = seq(from=0.05,to=1,by=0.05)
quantiles = quantile(comb$specH.mean, quantilesToRun)
res = data.frame()
qx =  quantiles[4]
qx
humidity.bin = c('humid','dry')[1+as.numeric(humidity < qx)]
names(humidity.bin) = names(humidity)
resx = runDiscrete(tree,tones.bin, humidity.bin,
iQ,dQ)
resx
qx = quantiles[5]
qx
qx = quantiles[6]
qx
humidity.bin = c('humid','dry')[1+as.numeric(humidity < qx)]
names(humidity.bin) = names(humidity)
# run discrete
resx = runDiscrete(tree,tones.bin, humidity.bin,
iQ,dQ)
resx
DrawRateGraph2(resx)
DrawRateGraph2(resx[[1]])
resx
z = resx[[1]]
z
z = resx[[1]][[1]]
z
z = resx[[1]][[1]][[1]]
z
DrawRateGraph2(resx[[1]][[1]][[1]])
DrawRateGraph2(resx[[1]][[1]])
library(ape)
setwd("~/Documents/MPI/ClimateAndLanguage/PHOIBLE_Replication/analysis/")
source("fitPagel.r")
runDiscrete = function(tree,x,y, iQ, dQ){
# fit discrete
fit.ape = NA
try(fit.ape<-fitPagel(tree,x,y,iQ=iQ,dQ=dQ,method='ace'))
return(list(list(fit.ape,table(x,y),qx)))
}
# single-rate model
iQ<-matrix(c(0,1,2,0,3,0,0,2,4,0,0,1,0,4,3,0),4,4,byrow=TRUE)
# differet rates for complex -> simple in humid and dry conditions
dQ =matrix(c(0,1,2,0,3,0,0,5,4,0,0,1,0,4,3,0),4,4,byrow=TRUE)
tree = read.nexus("../data/grollemund_et_al2015-d-place.NEXUS")
tree.t = read.csv("../data/grollemund_et_al2015-d-place_Taxa.csv", stringsAsFactors = F)
tree$tip.label = tree.t[match(tree$tip.label, tree.t$taxon),]$glottocode
p = read.csv("../data/phoibleTonesAndHumidity.csv", stringsAsFactors = F)
load('../../Phylogenetics/GlottologTree/ANU_Data.rDat')
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
anu$glottocode = g[match(anu$iso, g$hid),]$id
anu = anu[!is.na(anu$glottocode),]
anu = anu[!anu$glottocode %in% p$Glottocode,]
names(anu)[names(anu) %in% c("Number.of.tones","glottocode")] = c("Tones","Glottocode")
comb = rbind(anu[,c("Glottocode","Tones",'specH.mean')],
p[,c("Glottocode","Tones",'specH.mean')])
tree = drop.tip(tree, tree$tip.label[!tree$tip.label %in% comb$Glottocode])
tones = comb[match(tree$tip.label, comb$Glottocode),]$Tones
names(tones) = comb[match(tree$tip.label, comb$Glottocode),]$Glottocode
humidity = comb[match(tree$tip.label, comb$Glottocode),]$specH.mean
names(humidity) = comb[match(tree$tip.label, comb$Glottocode),]$Glottocode
tones.bin = c("simple","complex")[tones>=3]
humidity.bin = c('humid','dry')[1+as.numeric(humidity < qx)]
names(humidity.bin) = names(humidity)
resx = runDiscrete(tree,tones.bin, humidity.bin,
iQ,dQ)
library(ape)
setwd("~/Documents/MPI/ClimateAndLanguage/PHOIBLE_Replication/analysis/")
source("fitPagel.r")
runDiscrete = function(tree,x,y, iQ, dQ){
# fit discrete
fit.ape = NA
try(fit.ape<-fitPagel(tree,x,y,iQ=iQ,dQ=dQ,method='ace'))
return(list(list(fit.ape,table(x,y),qx)))
}
# single-rate model
iQ<-matrix(c(0,1,2,0,3,0,0,2,4,0,0,1,0,4,3,0),4,4,byrow=TRUE)
# differet rates for complex -> simple in humid and dry conditions
dQ =matrix(c(0,1,2,0,3,0,0,5,4,0,0,1,0,4,3,0),4,4,byrow=TRUE)
tree = read.nexus("../data/grollemund_et_al2015-d-place.NEXUS")
tree.t = read.csv("../data/grollemund_et_al2015-d-place_Taxa.csv", stringsAsFactors = F)
tree$tip.label = tree.t[match(tree$tip.label, tree.t$taxon),]$glottocode
p = read.csv("../data/phoibleTonesAndHumidity.csv", stringsAsFactors = F)
load('../../Phylogenetics/GlottologTree/ANU_Data.rDat')
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
anu$glottocode = g[match(anu$iso, g$hid),]$id
anu = anu[!is.na(anu$glottocode),]
anu = anu[!anu$glottocode %in% p$Glottocode,]
names(anu)[names(anu) %in% c("Number.of.tones","glottocode")] = c("Tones","Glottocode")
comb = rbind(anu[,c("Glottocode","Tones",'specH.mean')],
p[,c("Glottocode","Tones",'specH.mean')])
tree = drop.tip(tree, tree$tip.label[!tree$tip.label %in% comb$Glottocode])
tones = comb[match(tree$tip.label, comb$Glottocode),]$Tones
names(tones) = comb[match(tree$tip.label, comb$Glottocode),]$Glottocode
humidity = comb[match(tree$tip.label, comb$Glottocode),]$specH.mean
names(humidity) = comb[match(tree$tip.label, comb$Glottocode),]$Glottocode
tones.bin = c("simple","complex")[tones>=3]
tones.bin
tones.bin = c("simple","complex")[1+as.numeric(tones>=3)]
library(ape)
setwd("~/Documents/MPI/ClimateAndLanguage/PHOIBLE_Replication/analysis/")
source("fitPagel.r")
runDiscrete = function(tree,x,y, iQ, dQ){
# fit discrete
fit.ape = NA
try(fit.ape<-fitPagel(tree,x,y,iQ=iQ,dQ=dQ,method='ace'))
return(list(list(fit.ape,table(x,y),qx)))
}
# single-rate model
iQ<-matrix(c(0,1,2,0,3,0,0,2,4,0,0,1,0,4,3,0),4,4,byrow=TRUE)
# differet rates for complex -> simple in humid and dry conditions
dQ =matrix(c(0,1,2,0,3,0,0,5,4,0,0,1,0,4,3,0),4,4,byrow=TRUE)
tree = read.nexus("../data/grollemund_et_al2015-d-place.NEXUS")
tree.t = read.csv("../data/grollemund_et_al2015-d-place_Taxa.csv", stringsAsFactors = F)
tree$tip.label = tree.t[match(tree$tip.label, tree.t$taxon),]$glottocode
p = read.csv("../data/phoibleTonesAndHumidity.csv", stringsAsFactors = F)
load('../../Phylogenetics/GlottologTree/ANU_Data.rDat')
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
anu$glottocode = g[match(anu$iso, g$hid),]$id
anu = anu[!is.na(anu$glottocode),]
anu = anu[!anu$glottocode %in% p$Glottocode,]
names(anu)[names(anu) %in% c("Number.of.tones","glottocode")] = c("Tones","Glottocode")
comb = rbind(anu[,c("Glottocode","Tones",'specH.mean')],
p[,c("Glottocode","Tones",'specH.mean')])
tree = drop.tip(tree, tree$tip.label[!tree$tip.label %in% comb$Glottocode])
tones = comb[match(tree$tip.label, comb$Glottocode),]$Tones
names(tones) = comb[match(tree$tip.label, comb$Glottocode),]$Glottocode
humidity = comb[match(tree$tip.label, comb$Glottocode),]$specH.mean
names(humidity) = comb[match(tree$tip.label, comb$Glottocode),]$Glottocode
tones.bin = c("simple","complex")[1+as.numeric(tones>=3)]
quantilesToRun = seq(from=0.05,to=1,by=0.05)
quantiles = quantile(comb$specH.mean, quantilesToRun)
humidity.bin = c('humid','dry')[1+as.numeric(humidity < qx)]
names(humidity.bin) = names(humidity)
resx = runDiscrete(tree,tones.bin, humidity.bin,
iQ,dQ)
tones.bin
humidity.bin
tones.bin
names(tones.bin) = names(tones)
resx = runDiscrete(tree,tones.bin, humidity.bin,
iQ,dQ)
DrawRateGraph2(resx[[1]][[1]])
rex
resx
qx = quantiles[4]
qx
humidity.bin = c('humid','dry')[1+as.numeric(humidity < qx)]
names(humidity.bin) = names(humidity)
# run discrete
resx = runDiscrete(tree,tones.bin, humidity.bin,
iQ,dQ)
qx = quantiles[5]
humidity.bin = c('humid','dry')[1+as.numeric(humidity < qx)]
names(humidity.bin) = names(humidity)
# run discrete
resx = runDiscrete(tree,tones.bin, humidity.bin,
iQ,dQ)
DrawRateGraph2(resx[[1]][[1]])
resx
DrawRateGraph2(resx[[1]][[1]], independent = T)
DrawRateGraph2(resx[[1]][[1]])
title("Independnet")
title("Independnet", line = -1)
par(mfrow=c(1,2))
DrawRateGraph2(resx[[1]][[1]], independent = T)
title("Independent", line = -1)
DrawRateGraph2(resx[[1]][[1]])
title("Dependent", line = -1)
DrawRateGraph(resx[[1]][[1]])
DrawRateGraphWithHist(resx[[1]][[1]])
DrawRateGraph(resx[[1]][[1]])
resx[[1]][[1]]
?Arrows
library(ape)
setwd("~/Documents/MPI/ClimateAndLanguage/PHOIBLE_Replication/analysis/")
source("fitPagel.r")
runDiscrete = function(tree,x,y, iQ, dQ){
# fit discrete
fit.ape = NA
try(fit.ape<-fitPagel(tree,x,y,iQ=iQ,dQ=dQ,method='ace'))
return(list(list(fit.ape,table(x,y),qx)))
}
# single-rate model
iQ<-matrix(c(0,1,2,0,3,0,0,2,4,0,0,1,0,4,3,0),4,4,byrow=TRUE)
# differet rates for complex -> simple in humid and dry conditions
dQ =matrix(c(0,1,2,0,3,0,0,5,4,0,0,1,0,4,3,0),4,4,byrow=TRUE)
tree = read.nexus("../data/grollemund_et_al2015-d-place.NEXUS")
tree.t = read.csv("../data/grollemund_et_al2015-d-place_Taxa.csv", stringsAsFactors = F)
tree$tip.label = tree.t[match(tree$tip.label, tree.t$taxon),]$glottocode
p = read.csv("../data/phoibleTonesAndHumidity.csv", stringsAsFactors = F)
load('../../Phylogenetics/GlottologTree/ANU_Data.rDat')
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
anu$glottocode = g[match(anu$iso, g$hid),]$id
anu = anu[!is.na(anu$glottocode),]
anu = anu[!anu$glottocode %in% p$Glottocode,]
names(anu)[names(anu) %in% c("Number.of.tones","glottocode")] = c("Tones","Glottocode")
comb = rbind(anu[,c("Glottocode","Tones",'specH.mean')],
p[,c("Glottocode","Tones",'specH.mean')])
tree = drop.tip(tree, tree$tip.label[!tree$tip.label %in% comb$Glottocode])
tones = comb[match(tree$tip.label, comb$Glottocode),]$Tones
names(tones) = comb[match(tree$tip.label, comb$Glottocode),]$Glottocode
humidity = comb[match(tree$tip.label, comb$Glottocode),]$specH.mean
names(humidity) = comb[match(tree$tip.label, comb$Glottocode),]$Glottocode
tones.bin = c("simple","complex")[1+as.numeric(tones>=3)]
names(tones.bin) = names(tones)
# Estimate quantiles from whole distribution
quantilesToRun = seq(from=0.05,to=1,by=0.05)
quantiles = quantile(comb$specH.mean, quantilesToRun)
res = list()
for(qx in quantiles){
# set dry/humid by quantile
humidity.bin = c('humid','dry')[1+as.numeric(humidity < qx)]
names(humidity.bin) = names(humidity)
# run discrete
resx = runDiscrete(tree,tones.bin, humidity.bin,
iQ,dQ)
res[[length(res)+1]] = resx
}
library(blme)
m1blme = blmer(prop.vowels.scaled ~ 1 +
inventorySize +
(1+specH.mean.center|Family) +
(1+specH.mean.center|autotyp.area),
data=p)
m2blme = blmer(prop.vowels.scaled ~
specH.mean.center +
inventorySize +
(1+specH.mean.center|Family) +
(1+specH.mean.center|autotyp.area),
data=p)
---
title: "Vowels and humidity: PHOIBLE replication"
output: pdf_document
---
```{r warning=F, message=F}
library(lme4)
library(sjPlot)
library(ggplot2)
library(caret)
library(car)
library(MCMCglmm)
library(reshape2)
```
```{r echo=F, eval=F}
setwd("~/Documents/MPI/ClimateAndLanguage/PHOIBLE_Replication/analysis/")
```
```{r echo=F}
getMEText = function(r,ef, wald=NULL, showWald=F){
AIC = r[2,]$AIC
loglikDiff = signif(diff(r$logLik),2)
chi = round(r$Chisq[2],2)
df = r$`Chi Df`[2]
p = signif(r$`Pr(>Chisq)`[2],2)
wald.text = ""
if(!is.null(wald)){
est = signif(wald[1],2)
stder = signif(wald[2],2)
t = signif(wald[3],2)
wptext = ""
wald.text =  paste("beta = ",est,",")
if(showWald){
if(!is.na(wald[4])){
wptext = paste(", Wald p =",signif(wald[4],2))
}
wald.text = paste("beta = ",est,", std.err = ",stder, ", Wald t = ",t,wptext,';')
}
}
begin = 'There was no significant'
if(p <0.09){
begin = "There was a marginal"
}
if(p < 0.05){
begin = 'There was a significant'
}
return(paste(begin,ef,"(",wald.text,"log likelihood difference =",
loglikDiff,", df = ",df,", Chi Squared =", chi,", p = ",p,")."))
}
```
# Load data
The PHOIBLE database contains data for 1667 varieites with unique glottolog codes.  There are multiple sources for some languages.  PHOIBLE suggests a 'trump' source for each of these cases, which we select if available, otherwise we seleted the source with the highest number of phonemes listed.
```{r}
p = read.csv("../data/phoibleVowelsAndHumidity.csv")
p = p[complete.cases(p[,
c("Family",'autotyp.area',
'specH.mean')]),]
```
There are now `r nrow(p)` datapoints.
Transform, scale and center the data.  The proportion of vowels to consonants is ratio in theory, but in practice the values are constrained below 1.  In any case, the mdoel estimates differ very little using a log transformation or a simple scaling.
```{r}
pp = preProcess(p[,c('Tones','specH.mean')], method="BoxCox")
h.lambda = pp$bc$specH.mean$lambda
p$specH.mean.center = bcPower(p$specH.mean, lambda = h.lambda)
p$specH.mean.center = scale(p$specH.mean.center)
hist(p$specH.mean.center)
p$prop.vowels = p$Vowels/(p$Consonants + p$Vowels)
p$prop.vowels.scaled = scale(p$prop.vowels)
p$inventorySize = p$Consonants + p$Vowels
p$inventorySize = scale(p$inventorySize)
hist(p$prop.vowels.scaled)
```
# Plots
Plot the raw data:
```{r}
gx = ggplot(p, aes(y=prop.vowels, x=specH.mean)) +
geom_point() +stat_smooth() +
ylab("Proportion of vowels") +
xlab("Specific Humidity")
gx
# Write to file
pdf("../results/PropVowels_SpecH.pdf", width=4, height=4)
gx
dev.off()
```
Check for correlation between proportion of vowels and total inventory size:
```{r}
plot(p$prop.vowels, p$inventorySize)
cor.test(p$prop.vowels, p$inventorySize)
```
```{r}
p$inventorySize.cat = cut(p$inventorySize, quantile(p$inventorySize,seq(0,1,length.out = 3)), include.lowest = T)
gx = ggplot(p, aes(y=prop.vowels, x=specH.mean,
colour=inventorySize.cat)) +
geom_point() +stat_smooth() +
ylab("Proportion of vowels") +
xlab("Specific Humidity")
gx
```
# Mixed effects models
We run mixed effects models predicting the number proportion of vowels to consonants (`prop.vowels.scaled`). We start by building a null model with only random effects for language family (`Family`) and geographic area (`autotyp.area`) and random slopes for humidity (`specH.mean.center`).  Then we add fixed effects for the inventory size (`inventorySize`), the humidity and the interaction between the two.
```{r}
m0 = lmer(prop.vowels.scaled ~ 1 +
(1+specH.mean.center|Family) +
(1+specH.mean.center|autotyp.area),
data=p)
m1 = lmer(prop.vowels.scaled ~ 1 +
inventorySize +
(1+specH.mean.center|Family) +
(1+specH.mean.center|autotyp.area),
data=p)
m2 = lmer(prop.vowels.scaled ~
specH.mean.center +
inventorySize +
(1+specH.mean.center|Family) +
(1+specH.mean.center|autotyp.area),
data=p)
m3 = lmer(prop.vowels.scaled ~
inventorySize *
specH.mean.center +
(1+specH.mean.center|Family) +
(1+specH.mean.center|autotyp.area),
data=p)
m1blme = blmer(prop.vowels.scaled ~ 1 +
inventorySize +
(1+specH.mean.center|Family) +
(1+specH.mean.center|autotyp.area),
data=p)
m2blme = blmer(prop.vowels.scaled ~
specH.mean.center +
inventorySize +
(1+specH.mean.center|Family) +
(1+specH.mean.center|autotyp.area),
data=p)
m1b = lmer(prop.vowels.scaled ~ 1 +
inventorySize +
(1+specH.mean.center|Family) +
(0+specH.mean.center|autotyp.area),
data=p)
m2b = lmer(prop.vowels.scaled ~
specH.mean.center +
inventorySize +
(1+specH.mean.center|Family) +
(0+specH.mean.center|autotyp.area),
data=p)
anova(m1b,m2b)
anova(m0,m1,m2,m3)
summary(m2b)
summary(m2)
cor(ranef(m2)$autotyp.area[,1],ranef(m2)$autotyp.area[,2])
cor(ranef(m2)$Family[,1],ranef(m2)$Family[,2])
m1b = lmer(prop.vowels.scaled ~ 1 +
inventorySize +
(1+specH.mean.center|Family) +
(1|autotyp.area),
data=p)
m2b = lmer(prop.vowels.scaled ~
specH.mean.center +
inventorySize +
(1+specH.mean.center|Family) +
(1|autotyp.area),
data=p)
anova(m1b,m2b)
summary(m2b)
m1b = lmer(prop.vowels.scaled ~ 1 +
inventorySize +
(1+specH.mean.center|Family) +
(1|autotyp.area),
data=p)
m2b = lmer(prop.vowels.scaled ~
specH.mean.center +
inventorySize +
(1+specH.mean.center|Family) +
(1|autotyp.area),
data=p)
anova(m1b,m2b)
summary(m2b)
summary(m2)
anova(m0,m1,m2,m3)
---
title: "Measurement robustness for frequency of vowels"
output: pdf_document
---
# Introduction
Everett (2017) uses the frequency of vowels in the basic vocabulary (from the ASJP).  We can test the measurement robustness of this by looking at a wider range of words.  The database of words from Slonimska & Roberts (2017) was used (A collection of data from the Intercontinental Dictionary Series data, the World Loanword Database and Spraakbanken).  It consists of 999 concepts in 226 languages.  These were linked to the ASJP estimates for number of vowels.
# Test
Load libraries:
```{r message=FALSE, warning=F}
library(lme4)
library(ggplot2)
library(lattice)
library(sjPlot)
```
```{r echo=F, eval=F}
setwd("~/Documents/MPI/ClimateAndLanguage/PHOIBLE_Replication/analysis/")
```
Load data:
```{r}
d = read.csv("../data/ASJP_and_SlonimskaRoberts_VowelProportions.csv", stringsAsFactors = F)
d = d[complete.cases(d[,c("S.VProp","asjp.VProp")]),]
head(d)
dim(d)
